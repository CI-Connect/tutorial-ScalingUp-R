{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010906d8",
   "metadata": {},
   "source": [
    "# Scaling up compute resources\n",
    "\n",
    "Scaling up the computational resources is a big advantage for doing certain large scale calculations on OSPool. Consider the extensive sampling for a multi-dimensional Monte Carlo integration or molecular dynamics simulation with several initial conditions. These type of calculations require submitting a lot of jobs.\n",
    "\n",
    "About a million CPU hours per day are available to OSPool users on an opportunistic basis. Learning how to scale up and control large numbers of jobs is key to realizing the full potential of distributed high throughput computing on the OSPool. In this tutorial, we will see how to scale up calculations for a simple example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85ed70-930f-42eb-88f3-847ca5efefa8",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "For this example, we will use computational methods to estimate π. First, we will define a square inscribed by a unit circle from which we will randomly sample points. The ratio of the points outside the circle to the points in the circle is calculated, which approaches π/4.\n",
    "\n",
    "This method converges extremely slowly, which makes it great for a CPU-intensive exercise (but bad for a real estimation!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e24650-f032-4636-8a29-4aca0accb129",
   "metadata": {},
   "source": [
    "## Create and Test an R Script\n",
    "\n",
    "Our code is a simple R script that does the estimation. It takes in a single argument in order to differentiate the jobs. The code for the script is contained in the file mcpi.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aeb7bb3-0fa1-4c1c-a4bc-2beea56fef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "\n",
      "args = commandArgs(trailingOnly = TRUE)\n",
      "iternum = as.numeric(args[[1]]) + 100\n",
      "\n",
      "montecarloPi <- function(trials) {\n",
      "  count = 0\n",
      "  for(i in 1:trials) {\n",
      "    if((runif(1,0,1)^2 + runif(1,0,1)^2)<1) {\n",
      "      count = count + 1\n",
      "    }\n",
      "  }\n",
      "  return((count*4)/trials)\n",
      "}\n",
      " \n",
      "montecarloPi(iternum)\n"
     ]
    }
   ],
   "source": [
    "cat mcpi.R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906b940-4919-45bb-b9d4-bd54f89650a7",
   "metadata": {},
   "source": [
    "The header at the top of the file indicates that this script is meant to be run using R. \n",
    "\n",
    "If we were running a more intensive script, we would want to test our pipeline with a shortened, test script first.\n",
    "\n",
    "> If you want to test the script, start a separate terminal window and then run the following \n",
    "> two cmmands to start an R container, and then run \n",
    "> the script using `Rscript`: \n",
    "> \n",
    "> ```\n",
    "> $ singularity shell \\\n",
    ">     /cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-r:3.5.0\n",
    "> Singularity osgvo-r:3.5.0:~> ./mcpi.R 10\n",
    "> [1] 3.14\n",
    "> Singularity osgvo-r:3.5.0:~> exit\n",
    "> $ \n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e799147-0e65-4989-9ee5-95ff26efe1ca",
   "metadata": {},
   "source": [
    "## Create a Submit File and Log Directory\n",
    "\n",
    "Now that we have our R script written and tested, we can begin building the submit file for our job. If we want to submit several jobs, we need to track log, output, and error files for each job. An easy way to do this is to use the Cluster and Process ID values assigned by HTCondor to create unique files for each job in our overall workflow.\n",
    "\n",
    "In this example, the submit file is called `R.container.submit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0812e323-d24f-4779-89a5-e52e05e75792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe = container\n",
      "container_image = /cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-r:3.5.0\n",
      "\n",
      "executable = mcpi.R\n",
      "arguments = $(Process)\n",
      "\n",
      "#transfer_input_files = \n",
      "should_transfer_files = YES\n",
      "when_to_transfer_output = ON_EXIT\n",
      "\n",
      "log = logs/job.log.$(Cluster).$(Process)\n",
      "error = logs/job.error.$(Cluster).$(Process)\n",
      "output = output/mcpi.out.$(Cluster).$(Process)\n",
      "\n",
      "request_cpus = 1\n",
      "request_memory = 1GB\n",
      "request_disk = 1GB\n",
      "\n",
      "queue 100\n"
     ]
    }
   ],
   "source": [
    "cat R.container.submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1774e-ac43-4772-ab97-2e3779aa4c0a",
   "metadata": {},
   "source": [
    "There are several items to note about this submit file:\n",
    "\n",
    "* The `queue 100` statement in the submit file. This tells HTCondor to enqueue 100 copies of this job as one cluster.\n",
    "* The submit variables `$(Cluster)` and `$(Process)`. These are used to specify unique output files. HTCondor will replace these with the Cluster and Process ID numbers for each individual process within the submission. The `$(Process)` is also passed as an argument to our R script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7aabe",
   "metadata": {},
   "source": [
    "## Submit the Jobs\n",
    "\n",
    "Now it is time to submit our job! Submit the job with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f62114a-1b57-4331-819c-ed61b424ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job(s)....................................................................................................\n",
      "100 job(s) submitted to cluster 1.\n"
     ]
    }
   ],
   "source": [
    "condor_submit R.container.submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7522e-07b1-4aac-ad56-d723f23635f3",
   "metadata": {},
   "source": [
    "Apply your `condor_q` knowledge to see the progress of these jobs. Check you `logs` folder to see the error and HTCondor log files, and check the `output` folder to see the results of the scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dec47d-c4ec-4f83-8156-81f8c9d1b75f",
   "metadata": {},
   "source": [
    "## Post Process\n",
    "\n",
    "Once the jobs are completed, you can use the information in the output files \n",
    "to calculate an average of all of our computed estimates of &pi;.\n",
    "\n",
    "To see this, we can use the command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0881741c-e994-4d9d-ae2a-96d4e7dfcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12   1\n",
      "3.287129   2\n",
      "3.418182   3\n",
      "3.135135   4\n",
      "3.035714   5\n",
      "3.079646   6\n",
      "3.052632   7\n",
      "3.095652   8\n",
      "3.482759   9\n",
      "2.837607   10\n",
      "3.254237   11\n",
      "3.12605   12\n",
      "3.019608   13\n",
      "3.233333   14\n",
      "3.140496   15\n",
      "3.147541   16\n",
      "3.154472   17\n",
      "3.096774   18\n",
      "3.008   19\n",
      "3.238095   20\n",
      "2.992126   21\n",
      "3.25   22\n",
      "3.162791   23\n",
      "3.145631   24\n",
      "2.953846   25\n",
      "3.29771   26\n",
      "2.969697   27\n",
      "3.368421   28\n",
      "3.313433   29\n",
      "2.874074   30\n",
      "3.235294   31\n",
      "3.270073   32\n",
      "3.130435   33\n",
      "2.964029   34\n",
      "3.384615   35\n",
      "3.228571   36\n",
      "3.29078   37\n",
      "3.098592   38\n",
      "2.909091   39\n",
      "3.138889   40\n",
      "3.089655   41\n",
      "3.287671   42\n",
      "3.129252   43\n",
      "3.081081   44\n",
      "3.355705   45\n",
      "3.238095   46\n",
      "3.173333   47\n",
      "3.072848   48\n",
      "3.368421   49\n",
      "3.294118   50\n",
      "3.142857   51\n",
      "3.2   52\n",
      "2.923077   53\n",
      "3.133758   54\n",
      "2.936709   55\n",
      "3.144654   56\n",
      "3.320755   57\n",
      "3.125   58\n",
      "3.229814   59\n",
      "2.91358   60\n",
      "3.116564   61\n",
      "3.02439   62\n",
      "3.030303   63\n",
      "3.180723   64\n",
      "3.209581   65\n",
      "3.071429   66\n",
      "3.12426   67\n",
      "2.990654   68\n",
      "3.223529   69\n",
      "2.900585   70\n",
      "3.069767   71\n",
      "3.236994   72\n",
      "3.011494   73\n",
      "3.291429   74\n",
      "3.181818   75\n",
      "2.983051   76\n",
      "3.235955   77\n",
      "2.994413   78\n",
      "3.185185   79\n",
      "3.355556   80\n",
      "2.917127   81\n",
      "2.857143   82\n",
      "3.038251   83\n",
      "3.043478   84\n",
      "3.264865   85\n",
      "3.247312   86\n",
      "3.187166   87\n",
      "2.978723   88\n",
      "3.238095   89\n",
      "3.302752   90\n",
      "3.178947   91\n",
      "3.350785   92\n",
      "3.104167   93\n",
      "3.067358   94\n",
      "3.216495   95\n",
      "2.953846   96\n",
      "3.020408   97\n",
      "3.228426   98\n",
      "3.111111   99\n",
      "3.236181   100\n",
      "---------------\n",
      " Grand Average = 3.14062\n"
     ]
    }
   ],
   "source": [
    "cat output/mcpi.out* | awk '{ sum += $2; print $2\"   \"NR} END { print \"---------------\\n Grand Average = \" sum/NR }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193b712-dd4f-4b6b-9cee-09b82b9dc7e2",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "* Scaling up the number of jobs is crucial for taking full advantage of the computational resources of the OSPool.\n",
    "* Changing the `queue` statement allows the user to scale up the resources.\n",
    "* The `argument` option can be used to pass parameters to a job script.\n",
    "* The submit variables `$(Cluster)` and `$(Process)` can be used to name log files uniquely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
