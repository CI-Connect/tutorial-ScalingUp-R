{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "010906d8",
   "metadata": {},
   "source": [
    "# Scaling up compute resources\n",
    "\n",
    "Scaling up the computational resources is a big advantage for doing certain large scale calculations on OSPool. Consider the extensive sampling for a multi-dimensional Monte Carlo integration or molecular dynamics simulation with several initial conditions. These type of calculations require submitting a lot of jobs.\n",
    "\n",
    "About a million CPU hours per day are available to OSPool users on an opportunistic basis. Learning how to scale up and control large numbers of jobs is key to realizing the full potential of distributed high throughput computing on the OSPool. In this tutorial, we will see how to scale up calculations for a simple example. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd85ed70-930f-42eb-88f3-847ca5efefa8",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "For this example, we will use computational methods to estimate π. First, we will define a square inscribed by a unit circle from which we will randomly sample points. The ratio of the points outside the circle to the points in the circle is calculated, which approaches π/4.\n",
    "\n",
    "This method converges extremely slowly, which makes it great for a CPU-intensive exercise (but bad for a real estimation!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e24650-f032-4636-8a29-4aca0accb129",
   "metadata": {},
   "source": [
    "## Create and Test an R Script\n",
    "\n",
    "Our code is a simple R script that does the estimation. It takes in a single argument in order to differentiate the jobs. The code for the script is contained in the file mcpi.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aeb7bb3-0fa1-4c1c-a4bc-2beea56fef81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env Rscript\n",
      "\n",
      "args = commandArgs(trailingOnly = TRUE)\n",
      "iternum = as.numeric(args[[1]]) + 100\n",
      "\n",
      "montecarloPi <- function(trials) {\n",
      "  count = 0\n",
      "  for(i in 1:trials) {\n",
      "    if((runif(1,0,1)^2 + runif(1,0,1)^2)<1) {\n",
      "      count = count + 1\n",
      "    }\n",
      "  }\n",
      "  return((count*4)/trials)\n",
      "}\n",
      " \n",
      "montecarloPi(iternum)\n"
     ]
    }
   ],
   "source": [
    "cat mcpi.R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e906b940-4919-45bb-b9d4-bd54f89650a7",
   "metadata": {},
   "source": [
    "The header at the top of the file indicates that this script is meant to be run using R. \n",
    "\n",
    "If we were running a more intensive script, we would want to test our pipeline with a shortened, test script first.\n",
    "\n",
    "> If you want to test the script, start a separate terminal window and then run the following \n",
    "> two cmmands to start an R container, and then run \n",
    "> the script using `Rscript`: \n",
    "> \n",
    "> ```\n",
    "> $ singularity shell \\\n",
    ">     /cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-r:3.5.0\n",
    "> Singularity osgvo-r:3.5.0:~> ./mcpi.R 10\n",
    "> [1] 3.14\n",
    "> Singularity osgvo-r:3.5.0:~> exit\n",
    "> $ \n",
    "> ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e799147-0e65-4989-9ee5-95ff26efe1ca",
   "metadata": {},
   "source": [
    "## Create a Submit File and Log Directory\n",
    "\n",
    "Now that we have our R script written and tested, we can begin building the submit file for our job. If we want to submit several jobs, we need to track log, output, and error files for each job. An easy way to do this is to use the Cluster and Process ID values assigned by HTCondor to create unique files for each job in our overall workflow.\n",
    "\n",
    "In this example, the submit file is called `R.container.submit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0812e323-d24f-4779-89a5-e52e05e75792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "universe = container\n",
      "container_image = /cvmfs/singularity.opensciencegrid.org/opensciencegrid/osgvo-r:3.5.0\n",
      "\n",
      "executable = mcpi.R\n",
      "arguments = $(Process)\n",
      "\n",
      "#transfer_input_files \t= \n",
      "should_transfer_files \t= YES\n",
      "when_to_transfer_output = ON_EXIT\n",
      "\n",
      "output \t= output/mcpi.out.$(Cluster).$(Process)\n",
      "\n",
      "log \t= logs/job.log.$(Cluster).$(Process)\n",
      "error \t= logs/job.error.$(Cluster).$(Process)\n",
      "\n",
      "request_cpus = 1\n",
      "request_memory = 200MB\n",
      "request_disk = 300MB\n",
      "\n",
      "queue 100\n"
     ]
    }
   ],
   "source": [
    "cat R.container.submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c1774e-ac43-4772-ab97-2e3779aa4c0a",
   "metadata": {},
   "source": [
    "There are several items to note about this submit file:\n",
    "\n",
    "* The `queue 100` statement in the submit file. This tells HTCondor to enqueue 100 copies of this job as one cluster.\n",
    "* The submit variables `$(Cluster)` and `$(Process)`. These are used to specify unique output files. HTCondor will replace these with the Cluster and Process ID numbers for each individual process within the submission. The `$(Process)` is also passed as an argument to our R script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7aabe",
   "metadata": {},
   "source": [
    "## Submit the Jobs\n",
    "\n",
    "Now it is time to submit our job! Submit the job with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f62114a-1b57-4331-819c-ed61b424ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job(s)....................................................................................................\n",
      "100 job(s) submitted to cluster 1.\n"
     ]
    }
   ],
   "source": [
    "condor_submit R.container.submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7522e-07b1-4aac-ad56-d723f23635f3",
   "metadata": {},
   "source": [
    "Apply your `condor_q` knowledge to see the progress of these jobs. Check you `logs` folder to see the error and HTCondor log files, and check the `output` folder to see the results of the scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dec47d-c4ec-4f83-8156-81f8c9d1b75f",
   "metadata": {},
   "source": [
    "## Post Process\n",
    "\n",
    "Once the jobs are completed, you can use the information in the output files \n",
    "to calculate an average of all of our computed estimates of &pi;.\n",
    "\n",
    "To see this, we can use the command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0881741c-e994-4d9d-ae2a-96d4e7dfcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.88   1\n",
      "3.168317   2\n",
      "3.2   3\n",
      "3.027027   4\n",
      "3.285714   5\n",
      "2.973451   6\n",
      "3.263158   7\n",
      "3.026087   8\n",
      "3.137931   9\n",
      "3.282051   10\n",
      "2.949153   11\n",
      "3.092437   12\n",
      "2.980392   13\n",
      "3.3   14\n",
      "3.107438   15\n",
      "3.04918   16\n",
      "2.861789   17\n",
      "3   18\n",
      "2.944   19\n",
      "3.047619   20\n",
      "3.11811   21\n",
      "3.03125   22\n",
      "3.131783   23\n",
      "3.145631   24\n",
      "3.107692   25\n",
      "2.870229   26\n",
      "3.181818   27\n",
      "3.157895   28\n",
      "3.253731   29\n",
      "3.288889   30\n",
      "3.294118   31\n",
      "3.416058   32\n",
      "3.217391   33\n",
      "3.165468   34\n",
      "3.230769   35\n",
      "3.2   36\n",
      "3.245283   37\n",
      "2.953271   38\n",
      "3.296296   39\n",
      "3.155963   40\n",
      "---------------\n",
      " Grand Average = 3.12593\n"
     ]
    }
   ],
   "source": [
    "cat output/mcpi.out* | awk '{ sum += $2; print $2\"   \"NR} END { print \"---------------\\n Grand Average = \" sum/NR }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193b712-dd4f-4b6b-9cee-09b82b9dc7e2",
   "metadata": {},
   "source": [
    "## Key Points\n",
    "\n",
    "* Scaling up the number of jobs is crucial for taking full advantage of the computational resources of the OSPool.\n",
    "* Changing the `queue` statement allows the user to scale up the resources.\n",
    "* The `argument` option can be used to pass parameters to a job script.\n",
    "* The submit variables `$(Cluster)` and `$(Process)` can be used to name log files uniquely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
